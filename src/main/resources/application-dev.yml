quarkus:
  application:
    name: quarkus-message-service
  http:
    port: 8089
  # Deshabilitar Dev Services para usar servicios locales
  devservices:
    enabled: false
  smallrye-health:
    ui:
      enabled: true
  kafka-streams:
    health:
      enabled: false
  datasource:
    db-kind: postgresql
    username: postgres
    password: 12345
    # URL JDBC para Flyway (migraciones)
    jdbc:
      url: jdbc:postgresql://127.0.0.1:5432/erp_tlm_2021
    # URL Reactiva para runtime
    reactive:
      url: postgresql://127.0.0.1:5432/erp_tlm_2021
  hibernate-orm:
    database:
      generation: none  # Deshabilitado - usamos Flyway
    # Desactivar validación de schema temporalmente
    validate-in-dev-mode: false
  flyway:
    migrate-at-start: true
    baseline-on-migrate: true
    schemas: inbox_messages
    locations: db/migration
    table: flyway_schema_history
  swagger-ui:
    always-include: true
    path: /swagger-ui
  # Redis Cache Configuration
  redis:
    hosts: redis://127.0.0.1:6379
    timeout: 10s
    # Pool de conexiones
    max-pool-size: 20
    max-pool-waiting: 24
  cache:
    redis:
      # TTL por defecto para cache (30 minutos)
      expire-after-write: 30m
      # Prefijo para las keys
      prefix: "msg-svc"
  # Logging Configuration para ELK Stack
  log:
    console:
      # Habilitar logging JSON en consola para Logstash
      json: true
      format: "%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p [%c{3.}] (%t) %s%e%n"
    # Configurar niveles de log
    level: INFO
    category:
      "org.walrex":
        level: DEBUG
      "io.quarkus":
        level: INFO
      "org.hibernate":
        level: WARN
    # Configurar archivos de log (opcional, para desarrollo local)
    file:
      enable: true
      path: logs/application.log
      rotation:
        max-file-size: 10M
        max-backup-index: 5
        file-suffix: .yyyy-MM-dd
      format: "%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p [%c{3.}] (%t) %s%e%n"
kafka:
  bootstrap:
    servers: 127.0.0.1:9092
mp:
  messaging:
    # ===== CONFIGURACIÓN DE CONSUMIDORES (INCOMING) =====
    incoming:
      # Consumer para mensajes de inbox
      inbox-messages:
        connector: smallrye-kafka
        topic: inbox.messages
        # Deserializador Avro de Confluent
        value:
          deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
        key:
          deserializer: org.apache.kafka.common.serialization.StringDeserializer
        # Schema Registry
        schema:
          registry:
            url: http://127.0.0.1:8081
        specific:
          avro:
            reader: true
        # Configuración de consumo
        auto:
          offset:
            reset: earliest
        group:
          id: message-service-consumer-group
        # Eficiencia: procesar en batch
        batch: true
        max:
          poll:
            records: 500
        # Commit manual para control fino
        enable:
          auto:
            commit: false
        # Configuración de concurrencia
        # Si necesitas más throughput, aumenta esto junto con las particiones del topic
        # Por defecto Quarkus usa 1 thread por consumer
        # Para más paralelismo, puedes usar múltiples consumers con el mismo group.id

      # Consumer para eventos de notificación
      notification-events:
        connector: smallrye-kafka
        topic: notification.events
        value:
          deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
        key:
          deserializer: org.apache.kafka.common.serialization.StringDeserializer
        schema:
          registry:
            url: http://127.0.0.1:8081
        specific:
          avro:
            reader: true
        auto:
          offset:
            reset: earliest
        group:
          id: notification-consumer-group
        batch: false
        enable:
          auto:
            commit: true

    # ===== CONFIGURACIÓN DE PRODUCTORES (OUTGOING) =====
    outgoing:
      # Producer para mensajes de inbox
      inbox-messages-out:
        connector: smallrye-kafka
        topic: inbox.messages
        value:
          serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
        key:
          serializer: org.apache.kafka.common.serialization.StringSerializer
        schema:
          registry:
            url: http://127.0.0.1:8081
        auto:
          register:
            schemas: true
        use:
          latest:
            version: true
        # Eficiencia: batching de mensajes
        batch:
          size: 16384
        linger:
          ms: 10
        # Compresión para reducir red
        compression:
          type: snappy
        # Idempotencia para exactly-once (requiere acks: all)
        acks: all
        enable:
          idempotence: true

      # Producer para notificaciones
      notification-events-out:
        connector: smallrye-kafka
        topic: notification.events
        value:
          serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
        key:
          serializer: org.apache.kafka.common.serialization.StringSerializer
        schema:
          registry:
            url: http://127.0.0.1:8081
        auto:
          register:
            schemas: true
        use:
          latest:
            version: true
        batch:
          size: 16384
        linger:
          ms: 10
        compression:
          type: snappy
        # Idempotencia para exactly-once (requiere acks: all)
        acks: all
        enable:
          idempotence: true

# Configuración de Consul para Service Registration
consul:
  host: localhost
  port: 8500
  service:
    host: localhost
  health:
    check:
      # IP del host accesible desde contenedores Docker
      # - Por defecto: host.docker.internal (con auto-detección en Linux)
      # - Si falla, especificar manualmente la IP del gateway de Docker
      # - Obtener gateway con: docker inspect consul-server | grep Gateway
      # - Ej: 172.18.0.1, 172.17.0.1, etc.
      host: host.docker.internal
