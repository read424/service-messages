input {
  # Input desde TCP para logs JSON de Quarkus
  tcp {
    port => 5000
    codec => json_lines
    tags => ["quarkus", "tcp"]
  }

  # Input desde UDP para logs JSON de Quarkus
  udp {
    port => 5000
    codec => json_lines
    tags => ["quarkus", "udp"]
  }

  # Input desde archivos de log (opcional, si usas Filebeat)
  beats {
    port => 5044
    tags => ["filebeat"]
  }
}

filter {
  # Parsear el timestamp si viene en el log
  if [timestamp] {
    date {
      match => ["timestamp", "ISO8601", "yyyy-MM-dd'T'HH:mm:ss.SSSZ"]
      target => "@timestamp"
    }
  }

  # Agregar información adicional
  mutate {
    add_field => {
      "application" => "quarkus-message-service"
      "environment" => "${ENVIRONMENT:dev}"
    }
  }

  # Parsear el nivel de log
  if [level] {
    mutate {
      lowercase => ["level"]
    }
  }

  # Extraer información del logger
  if [loggerClassName] {
    grok {
      match => { "loggerClassName" => "(?<logger_package>(\w+\.)+)%{WORD:logger_class}" }
    }
  }

  # Agregar etiquetas basadas en el nivel de log
  if [level] == "error" or [level] == "ERROR" {
    mutate {
      add_tag => ["error"]
    }
  }

  if [level] == "warn" or [level] == "WARN" {
    mutate {
      add_tag => ["warning"]
    }
  }

  # Detectar si es un log de nuestra aplicación (org.walrex)
  if [loggerClassName] =~ /^org\.walrex/ {
    mutate {
      add_tag => ["application_log"]
    }
  }

  # Eliminar campos innecesarios o duplicados
  mutate {
    remove_field => ["host", "port"]
  }
}

output {
  # Enviar a Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "quarkus-logs-%{+YYYY.MM.dd}"
    # Crear template para el índice
    template_overwrite => true
  }

  # Output a consola para debugging (comentar en producción)
  stdout {
    codec => rubydebug
  }
}
